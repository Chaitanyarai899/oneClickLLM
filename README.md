# ğŸŒŸ One-Click LLM

One-Click LLM is an open-source solution that lets you deploy and run any LLM (Large Language Model) of your choice in the form of an API, compatible with the OpenAI library. It's a drop-in replacement for your projects that utilize the OpenAI library or any other API/library for LLMs.

With just a few clicks on the Web UI, you can select your preferred LLM, deploy it, and receive a custom Docker Compose file. This file can be run on any platform of your choice, such as an EC2 instance on AWS, Elastic Beanstalk, or a VM on Azure or GCP. ğŸš€

---

## ğŸ“š Features

- **Easy Deployment**: Deploy your LLM with just one click.
- **Custom Docker Compose**: Automatically generate a Docker Compose file for your chosen LLM.
- **Cloud Agnostic**: Run your LLM on any platform - AWS, Azure, GCP, or your local machine.
- **Open Source**: Contribute to the project, raise PRs for new features, or suggest improvements.
- **Astro Project**: Built using Astro, providing a fast and optimized development experience.

---

## ğŸ› ï¸ Tech Stack

- **Astro**: Frontend framework
- **Docker**: Containerization
- **Node.js**: Backend server
- **Shell Scripting**: COnfiguration
- **AWS, Azure, GCP**: Deployment options

---

## ğŸš€ Quick Start

### Prerequisites

- Node.js installed
- Git installed

### Steps to Build Locally

1. **Clone the Repository**:  
   ```bash
   git clone https://github.com/Chaitanyarai899/oneClickLLM
   ```
   
2. **Navigate to the Directory**:  
   ```bash
   cd oneClickLLM
   ```
   
3. **Install Dependencies**:  
   ```bash
   npm install
   ```
   
4. **Run the Development Server**:  
   ```bash
   npm run dev
   ```
   
Now, your project is up and running locally! ğŸ‰

---

## ğŸŒ Deploying on Your Own

If you wish to deploy this project on your own infrastructure:

1. **Build the Project**:  
   ```bash
   npm run build
   ```

2. **Deploy the Project**:  
   Deploy the project on any platform of your choice - AWS EC2, Azure VM, GCP VM, etc.

---

## ğŸ’» Usage

1. **Go to the Web UI**:  
   Open the browser and navigate to the Web UI.

2. **Select LLM**:  
   Choose the LLM of your choice from the list.

3. **Deploy**:  
   Hit deploy, and you will receive a custom Docker Compose file.

4. **Run Anywhere**:  
   Use the Compose file on any platform to run the LLM.

---

## ğŸ¤ Contributing

We welcome contributions! If you'd like to contribute:

1. Fork the repository.
2. Create a new branch.
3. Make your changes.
4. Submit a PR.

Feel free to raise a PR for any new feature or improvements. Let's build something amazing together! ğŸš€

---

## ğŸ“œ License

This project is licensed under the MIT License.

---

If you have any suggestions or need assistance, don't hesitate to reach out! ğŸ˜Š
